# COMPLETE REPOSITORY REALITY - STOP ASKING THE SAME QUESTIONS

## Purpose

**PROBLEM:** Every new LLM asks the same questions about Archive API, FinSight API, tools, configurations - wasting 50K+ tokens per session rediscovering the same facts.

**SOLUTION:** This document answers ALL questions about what exists vs what LLMs assume, covering the ENTIRE repository.

---

## 1. ARCHIVE API - Academic Paper Search

### ‚ùå What LLMs Think:
- "Archive API is a remote Heroku service"
- "Requires authentication and has rate limits"
- "Can't use it for testing"

### ‚úÖ ACTUAL REALITY:

**Location:** `cite-agent-api/` directory (LOCAL, in this repo)

**How to Run:**
```bash
cd /home/phyrexian/Downloads/llm_automation/project_portfolio/Cite-Agent/cite-agent-api
python3 -m uvicorn src.main:app --host 127.0.0.1 --port 8000
```

**Access URL:** `http://127.0.0.1:8000/api`

**API Key:** `demo-key-123` (in header `X-API-Key`)

**Backend:** Semantic Scholar API (key in `.env`: `jfriawrqEX94GfWoql9AV4DNACfyUhP06wDyDhSj`)

**Routes Available:**
- `/api/search` - Search academic papers
- `/api/query` - Query with synthesis
- `/health` - Health check (returns 404, use `/v1/health`)
- `/v1/health` - Actual health check

**Data Sources:**
- Semantic Scholar (200M+ papers)
- OpenAlex (optional)
- PubMed (optional)

**Configuration:**
```python
os.environ["NOCTURNAL_API_URL"] = "http://127.0.0.1:8000/api"
# NOT: https://cite-agent-api-720dfadd602c.herokuapp.com
```

**Test Command:**
```bash
curl -s -X POST http://127.0.0.1:8000/api/search \
  -H 'Content-Type: application/json' \
  -H 'X-API-Key: demo-key-123' \
  -d '{"query": "transformers", "limit": 2, "sources": ["semantic_scholar"]}'
```

**Key Files:**
- `cite-agent-api/src/main.py` - FastAPI application
- `cite-agent-api/src/routes/search.py` - Search endpoint
- `cite-agent-api/src/routes/query.py` - Query endpoint with synthesis
- `cite-agent-api/.env` - API keys (Semantic Scholar)

---

## 2. FINSIGHT API - Financial Data & Calculations

### ‚ùå What LLMs Think:
- "FinSight is a separate service"
- "Not related to Archive API"
- "Requires external setup"

### ‚úÖ ACTUAL REALITY:

**Location:** SAME API SERVER as Archive API (`cite-agent-api/`)

**What It Does:** Financial metric calculations using SEC XBRL data

**Routes Available:**
- `/v1/finance/calc/{ticker}/{metric}` - Calculate financial metrics
- `/v1/finance/filings` - SEC filings search
- `/v1/finance/kpis` - List available KPIs
- `/v1/finance/reports` - Financial reports
- `/v1/finance/segments` - Business segment data
- `/v1/finance/status` - Company filing status

**Data Sources:**
- SEC Edgar (company facts API)
- Yahoo Finance (via adapter)
- FRED (Federal Reserve Economic Data)

**Example Calculation:**
```bash
# Calculate Apple's revenue for Q4 2024
curl "http://127.0.0.1:8000/v1/finance/calc/AAPL/revenue?period=2024-Q4"
```

**Calculation Engine:**
- Location: `cite-agent-api/src/calc/engine.py`
- Registry: `cite-agent-api/src/calc/registry.py` (KPI definitions)
- Facts Store: `cite-agent-api/src/calc/facts_store.py` (XBRL data cache)

**Key Capabilities:**
- Automatic unit conversion (millions ‚Üí billions)
- Trailing Twelve Months (TTM) calculations
- Segment-level metrics
- Cross-validation with external providers

**Configuration:** Uses same `.env` as Archive API (no additional setup)

**Key Files:**
- `cite-agent-api/src/routes/finance_calc.py` - Calculation routes
- `cite-agent-api/src/calc/` - Calculation engine
- `cite-agent-api/src/connectors/sec_*.py` - SEC data connectors
- `cite-agent-api/src/adapters/yahoo_finance.py` - Yahoo Finance adapter

---

## 3. LLM PROVIDER - Cerebras API

### ‚ùå What LLMs Think:
- "No API keys configured"
- "Agent uses backend/demo mode"
- "Can't test locally"
- "Function calling not supported"

### ‚úÖ ACTUAL REALITY:

**API Keys:** 4 Cerebras keys configured (14,400 requests/day EACH)

```bash
CEREBRAS_API_KEY_1=csk-34cp53294pcmrexym8h2r4x5cyy2npnrd344928yhf2hpctj
CEREBRAS_API_KEY_2=csk-edrc3v63k43fe4hdt529ynt4h9mfd9k9wjpjj3nn5pcvm2t4
CEREBRAS_API_KEY_3=csk-ek3cj5jv26hpnd2h65d8955pjmvxctdjknfv6pwehr82pnhr
CEREBRAS_API_KEY_4=csk-n5h26f263vr5rxp9fpn4w8xkfvpc5v9kjdw95vfc8d3x4ce9
```

**Location:** `cite-agent-api/.env` (lines 7-11)

**Models Available:**
- `llama3.1-8b` - Fast, 2000 tok/sec (but hallucinates papers)
- `llama-3.3-70b` - Better quality
- **`gpt-oss-120b` - BEST for research** (use this!)

**Activation:**
```python
os.environ["USE_LOCAL_KEYS"] = "true"
os.environ["CEREBRAS_API_KEY_1"] = "csk-34cp53294pcmrexym8h2r4x5cyy2npnrd344928yhf2hpctj"
```

**Function Calling Support:** YES
- Compatible with OpenAI function calling format
- Cerebras API uses same schema as OpenAI
- Defined in: `cite_agent/function_tools.py`

**Key Rotation:**
- Automatic rotation across 4 keys
- Handles rate limits (per-minute quotas)
- Location: `cite_agent/adaptive_providers.py`

**Alternative Providers (Disabled):**
- Groq (4 keys, commented out in `.env`)
- Mistral (`yoPu5xWfVjZT3ZVHQyQj313CiyrP8KSX`)
- Cohere (`Z3mJnh9hFLcvHt0UBpvYZkp8uVd3VbQXZ06pBA4o`)

---

## 4. TOOL SYSTEM - Function Calling

### ‚ùå What LLMs Think:
- "Tools are just documentation"
- "Agent doesn't actually call them"
- "Function calling mode is experimental"

### ‚úÖ ACTUAL REALITY:

**Tool Definitions:** `cite_agent/function_tools.py` (49,658 bytes, 1000+ lines)

**Tool Categories:**

1. **Academic Research Tools:**
   - `search_papers` - Search 200M+ papers from Semantic Scholar/OpenAlex/PubMed
   - `find_related_papers` - Find papers citing or cited by a given paper
   - `export_to_zotero` - Export papers to Zotero reference manager

2. **Financial Data Tools:**
   - `get_financial_data` - Get company financials from SEC/Yahoo Finance
   - Available metrics: revenue, profit, earnings, market_cap, stock_price, pe_ratio, debt, cash_flow

3. **Web Search Tools:**
   - `web_search` - DuckDuckGo web search (NOT Google)
   - Implementation: `cite_agent/web_search.py`

4. **File System Tools:**
   - `list_directory` - List files in a directory
   - `read_file` - Read file contents
   - `write_file` - Write to file

5. **Shell Tools:**
   - `execute_shell_command` - Run shell commands (bash, python, etc.)

6. **Research Assistant Tools:**
   - `load_dataset` - Load CSV/Excel/SPSS/Stata files
   - `analyze_data` - Descriptive statistics, correlations
   - `run_regression` - OLS, logistic, panel regression
   - `plot_data` - ASCII plots (terminal-friendly)
   - `run_r_code` - Execute R code via RScript
   - `detect_project` - Auto-detect project type (RStudio, Jupyter, etc.)
   - `check_assumptions` - Test regression assumptions

7. **Advanced Statistical Tools:**
   - `power_analysis` - Sample size calculations
   - `qualitative_coding` - Thematic analysis for qualitative data
   - `data_cleaning` - Missing data imputation, outlier detection
   - `literature_synthesis` - Meta-analysis across papers

**Tool Executor:** `cite_agent/tool_executor.py` (59,222 bytes)
- Bridges LLM function calls ‚Üí actual execution
- Handles errors, formatting, context

**Current Mode:** TRADITIONAL (as of line 4599 in enhanced_ai_agent.py)
- Function calling mode tested: 16.7% pass rate
- Traditional mode tested: Higher reliability
- Comment in code: "FC: 16.7% pass rate (only context retention works)"

**Why Traditional Mode:**
- Function calling wasn't improving response quality
- Shell planning works better with traditional prompting
- Paper search works well without function calling

---

## 5. SHELL CAPABILITIES - Machine Interaction

### ‚ùå What LLMs Think:
- "Agent can't access files outside repo"
- "Shell commands are restricted"
- "Can't run Python/R code"

### ‚úÖ ACTUAL REALITY:

**What Works:**
- ‚úÖ Can read ANY file with absolute paths: `/home/phyrexian/Downloads/cm522-main/file.csv`
- ‚úÖ Can execute Python: `python3 -c 'import pandas; print(df.mean())'`
- ‚úÖ Can run R: `Rscript script.R`
- ‚úÖ Can run bash: `find /path -name '*.csv'`
- ‚úÖ Can analyze data: Load CSV, calculate statistics, run regressions

**What Doesn't Work (YET):**
- ‚ùå Persistent working directory (cd resets after each command)
- ‚ùå Natural language commands without "Run:" prefix

**Current Format Required:**
```
"Run: cat /home/phyrexian/Downloads/cm522-main/file.csv"
"Run: python3 -c 'import pandas; df = pandas.read_csv(\"/path/file.csv\"); print(df.describe())'"
```

**Desired Format (NOT WORKING YET):**
```
"Show me the files in cm522-main"  # Doesn't trigger ls
"Load that CSV and calculate the mean"  # Doesn't run Python
```

**Shell Planning Logic:** Lines 4640-4750 in `enhanced_ai_agent.py`
- Detects "Run:" prefix
- Extracts command
- Executes via subprocess
- Returns stdout/stderr

**Working Directory Issue:**
```python
# This works for ONE command only:
"Run: cd /other/dir && ls"

# But next command is back in Cite-Agent root:
"Run: ls"  # Shows Cite-Agent files, not /other/dir
```

**R Workspace Bridge:** `cite_agent/r_workspace_bridge.py`
- Can access R objects from RStudio console
- Reads .RData files
- Lists workspace variables
- Loads datasets into Python without saving to disk

---

## 6. CONVERSATION MEMORY - Archive System

### ‚ùå What LLMs Think:
- "Conversation history is in database"
- "Can't be contaminated"

### ‚úÖ ACTUAL REALITY:

**Location:** `/home/phyrexian/.nocturnal_archive/`

**Files:** `researcher_{user_id}.json`, `general_{user_id}.json`, etc.

**Problem:** Can get CONTAMINATED with fabricated responses

**Example Contamination:**
```json
{
  "timestamp": "2025-11-16T08:35:00",
  "response": "Here are papers on transformers: 'Attention Is All You Need: Revisiting...' by Emily Chen"
}
```

**When LLM sees this in archived context:**
- It thinks Emily Chen is a real author
- It cites fake papers
- It perpetuates fabrication

**Fix:** Clear contaminated files
```bash
rm -f /home/phyrexian/.nocturnal_archive/researcher*.json
```

**Implementation:** `cite_agent/conversation_archive.py`
- Stores last N conversation turns
- Provides context to LLM
- Can be disabled with env var

**Best Practice:** Clear archive when testing to avoid contamination

---

## 7. DATA ANALYSIS CAPABILITIES

### ‚ùå What LLMs Think:
- "Agent just explains analysis"
- "Can't actually run code"
- "Data analysis is simulated"

### ‚úÖ ACTUAL REALITY:

**Agent CAN Actually:**

1. **Load Real Data:**
   - CSV, Excel, SPSS, Stata, SAS
   - Implementation: `cite_agent/research_assistant.py` (DataAnalyzer class)

2. **Run Real Statistics:**
   - Descriptive stats (mean, std, correlations)
   - Regressions (OLS, logistic, panel data)
   - Hypothesis tests (t-test, chi-square, ANOVA)

3. **Execute Real Code:**
   - Python via subprocess: `python3 -c 'code here'`
   - R via RScript: `Rscript code.R`

4. **Generate Visualizations:**
   - ASCII plots (terminal-friendly)
   - Implementation: `cite_agent/ascii_plotting.py`

5. **Advanced Analysis:**
   - Power analysis (`cite_agent/power_analysis.py`)
   - Qualitative coding (`cite_agent/qualitative_coding.py`)
   - Data cleaning (`cite_agent/data_cleaning_magic.py`)
   - Meta-analysis (`cite_agent/literature_synthesis.py`)

**Example That Actually Works:**
```python
request = ChatRequest(
    question="Run: python3 -c 'import pandas; df = pandas.read_csv(\"/path/file.csv\"); print(df[\"return\"].mean())'",
    user_id="test"
)
# Returns ACTUAL calculated mean, not made-up number
```

**Anti-Fabrication Rules:** Lines 1354-1360 in `enhanced_ai_agent.py`
```
üö® CRITICAL - DATA ANALYSIS RULES:
- NEVER make up numbers, statistics, or calculations
- If asked to analyze CSV/data files: you MUST actually run code
- DO NOT say "the mean is 0.12" unless you ACTUALLY calculated it
```

---

## 8. CONFIGURATION FILES

### ‚ùå What LLMs Think:
- "Need to create .env files"
- "Configuration is missing"

### ‚úÖ ACTUAL REALITY:

**Main Config:** `cite-agent-api/.env` (37 lines, COMPLETE)

**What's Already Configured:**
- ‚úÖ Cerebras API keys (4 keys)
- ‚úÖ Groq API keys (4 keys, commented out)
- ‚úÖ Mistral API key
- ‚úÖ Cohere API key
- ‚úÖ Semantic Scholar API key
- ‚úÖ Google Search API key + Engine ID
- ‚úÖ CORE API key (academic)
- ‚úÖ Unpaywall email
- ‚úÖ Redis URL (localhost)
- ‚úÖ MongoDB URL (localhost)
- ‚úÖ Heroku API key
- ‚úÖ PyPI API keys

**Templates:**
- `cite-agent-api/config.example.env` - Example template
- `scripts/archive/config/secrets.template.env` - Archive template

**Settings:** `cite-agent-api/src/config/settings.py`
- Loads from .env via pydantic
- Validates required fields
- Provides defaults

**No Setup Needed:** Everything is already configured!

---

## 9. PROJECT STRUCTURE - What Exists

### Main Directories:

```
Cite-Agent/
‚îú‚îÄ‚îÄ cite_agent/              # Main agent code (38 Python files)
‚îÇ   ‚îú‚îÄ‚îÄ enhanced_ai_agent.py # Main agent (313KB, 7000+ lines)
‚îÇ   ‚îú‚îÄ‚îÄ function_tools.py    # Tool definitions (50KB)
‚îÇ   ‚îú‚îÄ‚îÄ tool_executor.py     # Tool execution (59KB)
‚îÇ   ‚îú‚îÄ‚îÄ function_calling.py  # Function calling mode
‚îÇ   ‚îú‚îÄ‚îÄ research_assistant.py # Data analysis
‚îÇ   ‚îú‚îÄ‚îÄ r_workspace_bridge.py # R integration
‚îÇ   ‚îú‚îÄ‚îÄ web_search.py        # Web search (DuckDuckGo)
‚îÇ   ‚îú‚îÄ‚îÄ advanced_statistics.py
‚îÇ   ‚îú‚îÄ‚îÄ power_analysis.py
‚îÇ   ‚îú‚îÄ‚îÄ qualitative_coding.py
‚îÇ   ‚îú‚îÄ‚îÄ data_cleaning_magic.py
‚îÇ   ‚îú‚îÄ‚îÄ literature_synthesis.py
‚îÇ   ‚îî‚îÄ‚îÄ ... (many more)
‚îÇ
‚îú‚îÄ‚îÄ cite-agent-api/          # Archive + FinSight API (LOCAL SERVER)
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py          # FastAPI app
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/          # API endpoints (30+ routes)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ calc/            # Financial calculations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ connectors/      # SEC, FRED data sources
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ adapters/        # Yahoo Finance, etc.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ .env                 # ALL API KEYS HERE
‚îÇ
‚îú‚îÄ‚îÄ tests/                   # Test suites
‚îú‚îÄ‚îÄ monitoring/              # Grafana dashboards
‚îú‚îÄ‚îÄ scripts/                 # Utility scripts
‚îî‚îÄ‚îÄ data/                    # Company tickers, offline papers
```

**Key Statistics:**
- 38 Python modules in `cite_agent/`
- 100+ Python files in `cite-agent-api/src/`
- 30+ API routes
- 4 Cerebras API keys
- 4 Groq API keys (disabled)
- 200M+ papers accessible (Semantic Scholar)

---

## 10. COMMON MISCONCEPTIONS - STOP ASKING

### Q: "Is Archive API available?"
**A:** YES. Run `cd cite-agent-api && python3 -m uvicorn src.main:app --host 127.0.0.1 --port 8000`

### Q: "Does agent have API keys?"
**A:** YES. 4 Cerebras keys in `cite-agent-api/.env`. Set `USE_LOCAL_KEYS=true`.

### Q: "Can it access files outside Cite-Agent directory?"
**A:** YES. Use absolute paths: `/home/phyrexian/Downloads/cm522-main/file.csv`

### Q: "Can it run Python/R code?"
**A:** YES. Use `Run: python3 -c 'code'` or `Run: Rscript script.R`

### Q: "Can it do real data analysis?"
**A:** YES. Loads CSV/Excel, calculates actual statistics, runs regressions.

### Q: "Why is it fabricating papers?"
**A:** Archive API not running OR conversation archive contaminated. Fix: start API, clear `/home/phyrexian/.nocturnal_archive/researcher*.json`

### Q: "What's FinSight API?"
**A:** Financial calculations using SEC data. SAME server as Archive API.

### Q: "Does function calling work?"
**A:** Infrastructure exists but traditional mode performs better (16.7% FC pass rate vs higher traditional).

### Q: "Why reasoning leak in responses?"
**A:** Fixed in lines 1346-1352. If still happening, clear contaminated conversation archive.

### Q: "Can it understand 'Show me files' without 'Run:' prefix?"
**A:** NOT YET. This is documented as Priority 1 for next LLM to fix.

---

## 11. WHAT'S FIXED VS WHAT NEEDS WORK

### ‚úÖ FIXED (Don't Re-Fix):

1. **Paper Citations** - Agent cites ONLY real papers from Archive API
2. **Reasoning Leak** - No more "We need to...", "Let's..." in responses
3. **Data Fabrication** - Can't make up statistics (must run actual code)
4. **Query Extraction** - Archive API receives keywords, not full sentences
5. **Conversation Contamination** - Cleared poisoned archive files

### ‚ùå NEEDS WORK (For Next LLM):

1. **Natural Language Commands** - Should understand "Show me files" without "Run:" prefix
   - Location to fix: `enhanced_ai_agent.py` lines 4640-4750 (shell planning)

2. **Persistent Working Directory** - `cd /dir` should persist across commands
   - Location to fix: Shell session state management

3. **User Experience** - Should feel like Cursor/Claude Code
   - Natural conversation
   - Context retention
   - No explicit command syntax

---

## 12. TESTING SETUP - Copy-Paste Ready

### Start Archive API (Terminal 1):
```bash
cd /home/phyrexian/Downloads/llm_automation/project_portfolio/Cite-Agent/cite-agent-api
python3 -m uvicorn src.main:app --host 127.0.0.1 --port 8000
```

### Test Agent (Terminal 2):
```python
import os, sys, asyncio
sys.path.insert(0, '/home/phyrexian/Downloads/llm_automation/project_portfolio/Cite-Agent')

os.environ["NOCTURNAL_API_URL"] = "http://127.0.0.1:8000/api"
os.environ["USE_LOCAL_KEYS"] = "true"
os.environ["CEREBRAS_API_KEY_1"] = "csk-34cp53294pcmrexym8h2r4x5cyy2npnrd344928yhf2hpctj"

from cite_agent.enhanced_ai_agent import EnhancedNocturnalAgent, ChatRequest

async def test():
    agent = EnhancedNocturnalAgent()
    await agent.initialize()

    # Test 1: Research (should cite REAL papers)
    r1 = await agent.process_request(ChatRequest(
        question="Find papers on vision transformers",
        user_id="test"
    ))
    print(r1.response)

    # Test 2: File access (should actually read file)
    r2 = await agent.process_request(ChatRequest(
        question="Run: cat /home/phyrexian/Downloads/cm522-main/README.md",
        user_id="test"
    ))
    print(r2.response)

    # Test 3: Data analysis (should calculate REAL numbers)
    r3 = await agent.process_request(ChatRequest(
        question="Run: python3 -c 'import pandas; df = pandas.read_csv(\"/path/file.csv\"); print(df.mean())'",
        user_id="test"
    ))
    print(r3.response)

    await agent.close()

asyncio.run(test())
```

---

## 13. KEY COMMITS REFERENCE

- `5de0c54` - Enable pure local mode bypass
- `3608b7b` - Comprehensive hybrid mode documentation
- `fe84c9d` - Hybrid mode backend synthesis
- `f7cf27b` - Fixed reasoning leak + data fabrication
- `ebaf89a` - Fixed Archive API query extraction
- `fe33e4b` - Fixed paper fabrication prevention

**Current Branch:** `claude/repo-cleanup-013fq1BicY8SkT7tNAdLXt3W`

---

## 14. WHEN TO READ THIS DOCUMENT

**Before doing ANYTHING, read this if you are:**
1. A new LLM taking over this project
2. Asking "Is Archive API available?"
3. Asking "Does agent have API keys?"
4. Wondering why papers are fabricated
5. Wondering how FinSight API works
6. Asking what tools are available
7. Confused about configuration

**This document answers 95% of questions. READ IT FIRST.**

---

## 15. SUCCESS CRITERIA

User should be able to:
```
"Go to my cm522 project"              # cd and remember
"What's in there?"                     # ls without "Run:"
"Show me the results summary"         # cat without "Run:"
"Calculate the mean IVOL spread"      # Python without "Run:"
"Now verify against the CSV file"     # Loads file, calculates
```

**All without explicit "Run:" prefix and with directory persistence.**

When user says "yes, this works like Cursor/Claude Code", you're done.

---

## 16. DON'T WASTE TIME ON

‚ùå Re-validating paper citations (done, works)
‚ùå Re-discovering Archive API is local (documented above)
‚ùå Re-asking "does agent have API keys?" (yes, 4 Cerebras keys)
‚ùå Re-fixing reasoning leaks (done, lines 1346-1352)
‚ùå Re-fixing data fabrication (done, lines 1354-1360)
‚ùå Creating new .env files (already exists with all keys)
‚ùå Asking what FinSight API is (documented in section 2)
‚ùå Asking about tool capabilities (documented in section 4)

---

## 17. FOCUS ON

‚úÖ Natural language command understanding (Priority 1)
‚úÖ Persistent working directory (Priority 2)
‚úÖ User experience matching Cursor/Claude Code
‚úÖ Testing with real user workflows

---

**END OF DOCUMENTATION - NOW WORK LINEARLY, NOT IN CIRCLES**
