#!/usr/bin/env python3
"""
COMPREHENSIVE v1.5.6 Testing - Real Tool Sequencing
Tests actual multi-tool workflows with complex scenarios
"""

import subprocess
import sys
import time

def run_test(name, query, expect_sequencing=False):
    """Run a test query and show results"""
    print(f"\n{'='*80}")
    print(f"TEST: {name}")
    print(f"Query: {query}")
    print(f"Expected: Multi-step={expect_sequencing}")
    print('='*80)
    
    start = time.time()
    try:
        result = subprocess.run(
            ['cite-agent', query],
            capture_output=True,
            text=True,
            timeout=60
        )
        elapsed = time.time() - start
        
        output = result.stdout + result.stderr
        
        # Check for key indicators
        has_sequencing = 'Needs sequencing: True' in output or 'step workflow' in output.lower()
        has_error = 'error' in output.lower() or 'traceback' in output.lower()
        response_start = output.find('üìù Response:')
        
        if response_start >= 0:
            response = output[response_start:].split('\n', 10)[:10]
            print("RESPONSE:")
            for line in response:
                print(f"  {line}")
        
        print(f"\n‚è±Ô∏è  Time: {elapsed:.1f}s")
        print(f"üîÄ Sequencing: {'YES' if has_sequencing else 'NO'}")
        print(f"‚ùå Errors: {'YES' if has_error else 'NO'}")
        
        if expect_sequencing and not has_sequencing:
            print("‚ö†Ô∏è  WARNING: Expected sequencing but didn't happen")
        
        return not has_error
        
    except subprocess.TimeoutExpired:
        print("‚ùå TIMEOUT (60s)")
        return False
    except Exception as e:
        print(f"‚ùå ERROR: {e}")
        return False


def main():
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  CITE-AGENT v1.5.6 COMPREHENSIVE TOOL SEQUENCING TEST       ‚ïë
‚ïë  Testing REAL multi-tool workflows with complex scenarios    ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
""")

    tests = [
        # === CATEGORY 1: Multi-Step Mathematical Analysis ===
        (
            "Multi-step Math: Factorial ‚Üí Multiply ‚Üí Check Prime",
            "Calculate 7 factorial, multiply that result by 3, then tell me if the final number is prime or composite",
            True
        ),
        (
            "Multi-step Statistics: Generate ‚Üí Calculate ‚Üí Compare",
            "Calculate the mean of the numbers 15, 25, 35, 45, 55. Then calculate the median. Finally tell me which is larger.",
            True
        ),
        
        # === CATEGORY 2: Research ‚Üí Analysis Workflows ===
        (
            "Research ‚Üí Filter ‚Üí Extract Citation",
            "Search for papers about 'transformer models' from 2020 onwards, find the most cited one, and tell me its citation count",
            True
        ),
        (
            "Research ‚Üí Compare Papers",
            "Find papers about 'BERT' and papers about 'GPT', then tell me which topic has more papers published after 2019",
            True
        ),
        
        # === CATEGORY 3: Shell ‚Üí Analysis Workflows ===
        (
            "Shell ‚Üí Count ‚Üí Compare",
            "Count how many .md files are in the current directory, then count how many .py files, then tell me which type has more files",
            True
        ),
        (
            "Shell ‚Üí Read ‚Üí Analyze",
            "List all Python files in cite_agent/ directory, find the one with 'ai' in its name, and tell me approximately how many lines it has",
            True
        ),
        
        # === CATEGORY 4: Data ‚Üí Calculate ‚Üí Compare ===
        (
            "Shell Data ‚Üí Statistics ‚Üí Threshold",
            "Run 'echo 10,20,30,40,50 > /tmp/test_data.txt', read that file, calculate the average, and tell me if it's above 25",
            True
        ),
        
        # === CATEGORY 5: Cross-Domain Complex Workflows ===
        (
            "Research ‚Üí Shell ‚Üí Analysis Combined",
            "Search for a paper about 'attention mechanism', save its title, then count how many words are in that title",
            True
        ),
        (
            "Math ‚Üí Compare ‚Üí Research",
            "Calculate 100 divided by 7. Then search for papers that have approximately that many citations (around 14).",
            True
        ),
        
        # === CATEGORY 6: Simple Baseline Tests ===
        (
            "Simple: Direct Calculation",
            "What is 123 times 456?",
            False
        ),
        (
            "Simple: Direct Research",
            "Find one paper about machine learning",
            False
        ),
        (
            "Simple: Direct Shell",
            "Run: pwd",
            False
        ),
    ]

    results = []
    for test_name, query, expect_seq in tests:
        passed = run_test(test_name, query, expect_seq)
        results.append((test_name, passed))
        time.sleep(2)  # Rate limiting

    # Summary
    print(f"\n{'='*80}")
    print("COMPREHENSIVE TEST SUMMARY")
    print('='*80)
    
    passed = sum(1 for _, p in results if p)
    total = len(results)
    
    for name, p in results:
        status = "‚úÖ PASS" if p else "‚ùå FAIL"
        print(f"{status}: {name}")
    
    print(f"\nüìä TOTAL: {passed}/{total} passed ({100*passed//total}%)")
    
    if passed < total * 0.8:
        print("\n‚ö†Ô∏è  WARNING: Less than 80% pass rate - needs work")
        return 1
    elif passed == total:
        print("\nüéâ PERFECT SCORE - Ready to ship!")
        return 0
    else:
        print("\n‚úÖ GOOD - Most features working")
        return 0


if __name__ == '__main__':
    sys.exit(main())
